############## == $alfred_name == ###################
def $alfred_name_cmd(**context):
    ti = context['task_instance']
    run_id = context["dag_run"].run_id
    conf = context["dag_run"].conf
    job_id = ti.hostname

    params=dict(var_key_lst.get("common", {}).items() + var_key_lst.get("$alfred_name", {}).items())

    write_hosts = 'echo "192.168.1.28    spark.master" >> /etc/hosts'
    print(write_hosts)
    print(subprocess.check_output(write_hosts, shell=True, stderr=subprocess.STDOUT))

    install_phcli = 'apt-get update && apt install -f -y postgresql-server-dev-all && pip3 install phcli==1.0.3'
    print(install_phcli)
    print(subprocess.check_output(install_phcli, shell=True, stderr=subprocess.STDOUT))

    exec_phcli_submit = 'phcli maxauto --runtime $runtime --group $alfred_jobs_dir --path $alfred_name --cmd submit --job_id "{}" --context "{}" "{}"'.format(str(job_id), str(params), str(conf))
    print(exec_phcli_submit)
    print(subprocess.check_output(exec_phcli_submit, shell=True, stderr=subprocess.STDOUT))

    # key = ti.xcom_pull(task_ids='test', key='key').decode("UTF-8")
    # ti.xcom_push(key="key", value=key)

$alfred_name = PythonOperator(
    task_id='$alfred_name',
    provide_context=True,
    python_callable=$alfred_name_cmd,
    dag=dag
)
############## == $alfred_name == ###################

